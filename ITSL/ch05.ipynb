{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab - Cross Validation and Bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from ISLP import load_data\n",
    "from ISLP.models import (ModelSpec as MS,\n",
    "summarize ,\n",
    "poly)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from sklearn.model_selection import \\\n",
    "(cross_validate ,\n",
    "KFold ,\n",
    "ShuffleSplit)\n",
    "from sklearn.base import clone\n",
    "from ISLP.models import sklearn_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation Set Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We explore the use of the validation set approach. \n",
    "\n",
    "We use train_test_split() to split the data into training and validation sets. Then we can fit a model using only the observations from the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Auto = load_data('Auto')\n",
    "Auto_train, Auto_valid = train_test_split(Auto, test_size=196, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_mm = MS(['horsepower'])\n",
    "X_train = hp_mm.fit_transform(Auto_train)\n",
    "y_train = Auto_train['mpg']\n",
    "model = sm.OLS(y_train, X_train)\n",
    "results = model.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now use the predict() method of results on the validation data. We also calculate the validation MSE for our model. It turns out our Test MSE is 23.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23.61661706966988"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid = hp_mm.transform(Auto_valid)\n",
    "y_valid = Auto_valid['mpg']\n",
    "valid_pred = results.predict(X_valid)\n",
    "np.mean((y_valid - valid_pred) ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's generalize calculating the Test MSE with a function and let's estimate it for linear, quadratic and cubic fits. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalMSE(terms, response, train, test): \n",
    "    mm = MS(terms)\n",
    "    X_train = mm.fit_transform(train)\n",
    "    y_train = train[response]\n",
    "\n",
    "    X_test = mm.transform(test)\n",
    "    y_test = test[response]\n",
    "\n",
    "    results = sm.OLS(y_train, X_train).fit()\n",
    "    test_pred = results.predict(X_test)\n",
    "\n",
    "    return np.mean((test_pred - y_test ) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'PolynomialFeatures' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/andreafranceschini/Documents/Coding/bemacs/ITSL/ch05.ipynb Cell 12\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/andreafranceschini/Documents/Coding/bemacs/ITSL/ch05.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m MSE \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros(\u001b[39m3\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/andreafranceschini/Documents/Coding/bemacs/ITSL/ch05.ipynb#X14sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfor\u001b[39;00m idx, degree \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m,\u001b[39m4\u001b[39m)): \n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/andreafranceschini/Documents/Coding/bemacs/ITSL/ch05.ipynb#X14sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     MSE[idx] \u001b[39m=\u001b[39m evalMSE([poly(\u001b[39m'\u001b[39m\u001b[39mhorsepower\u001b[39m\u001b[39m'\u001b[39m, degree)], \u001b[39m'\u001b[39m\u001b[39mmpg\u001b[39m\u001b[39m'\u001b[39m, Auto_train, Auto_valid)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/andreafranceschini/Documents/Coding/bemacs/ITSL/ch05.ipynb#X14sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m MSE\n",
      "\u001b[0;31mTypeError\u001b[0m: 'PolynomialFeatures' object is not callable"
     ]
    }
   ],
   "source": [
    "MSE = np.zeros(3)\n",
    "\n",
    "for idx, degree in enumerate(range(1,4)): \n",
    "    MSE[idx] = evalMSE([poly('horsepower', degree)], 'mpg', Auto_train, Auto_valid)\n",
    "\n",
    "MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simplest way to cross validate in python is using sklearn, which has a different interface than statsmodels. \n",
    "\n",
    "cross_validate takes an optional parameter cv that indicates the K-fold for K-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19549935010445704"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "\n",
    "X, Y = Auto[['horsepower']], Auto['mpg']\n",
    "cv_results = cross_validate(model, X, Y, cv=10) # specifying cv does a k-fold cross validation\n",
    "# the fact that we provided the shape of the dataset means that we will perform Leave-One-Out CV (LOOCV)\n",
    "cv_err = np.mean(cv_results['test_score'])\n",
    "cv_err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We repeat this for various degrees of the polynomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-24.09767573, -19.17888986, -19.21385952, -19.21280702,\n",
       "       -18.75799181])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_error = np.zeros(5)\n",
    "Y = Auto['mpg']\n",
    "cv = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "model = LinearRegression()\n",
    "\n",
    "for idx, degree in enumerate(range(1,6)): \n",
    "    col = f'degree_{degree}'\n",
    "    poly = PolynomialFeatures(degree=degree)\n",
    "    poly_features = poly.fit_transform(Auto[['horsepower']])\n",
    "\n",
    "    cv_results = cross_validate(model, \n",
    "                                poly_features, \n",
    "                                Y, \n",
    "                                cv=cv,\n",
    "                                scoring='neg_mean_squared_error')\n",
    "    cv_error[idx] = np.mean(cv_results['test_score'])\n",
    "\n",
    "cv_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-27.43993365 -21.23584006 -21.33660618 -21.35388699 -20.90567054]\n"
     ]
    }
   ],
   "source": [
    "print(cv_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "Portfolio = load_data('Portfolio')\n",
    "def alpha_func(D,idx): \n",
    "    cov_ = np.cov(D[['X', 'Y']].loc[idx], rowvar=False)\n",
    "    # this returns an estimate for alpha\n",
    "    return ((cov_[1,1] - cov_[0,1]) / (cov_[0,0] + cov_[1,1,] - 2 * cov_[0,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6074452469619004"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_func(Portfolio, range(100))\n",
    "\n",
    "# now we choose the indices randomly\n",
    "rng = np.random.default_rng(0)\n",
    "alpha_func(Portfolio, rng.choice(100,100,replace=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We generalize the function. boot_SE finds the standard error estimate for a parameter (in this case $\\alpha$). The function runs the bootstrap $B$ times selecting $n$ elements from the sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Â we generalize with a function\n",
    "def boot_SE(func,D,n=None,B=1000,seed=0): \n",
    "    rng = np.random.default_rng(seed)\n",
    "    first_, second_ = 0, 0\n",
    "    n = n or D.shape[0]\n",
    "\n",
    "    for _ in range(B): \n",
    "        idx = rng.choice(D.index, n,replace=True)\n",
    "        value = func(D,idx)\n",
    "        first_ += value\n",
    "        second_ += value ** 2\n",
    "\n",
    "    return np.sqrt(second_ / B - (first_ / B) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09118176521277699"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_SE = boot_SE(alpha_func, Portfolio, B=1000, seed=0)\n",
    "alpha_SE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bootstrap can be used to assess the variability (SE) of the coefficients and predictions from a statistical learning method. \n",
    "\n",
    "Let's estimate the variability in the coefficients $\\beta_0,\\beta_1$, for the linear regression that estimates mpg from horsepower in the Auto dataset. We then compare the results to the traditional formulas for $SE(\\hat{\\beta_0}), SE(\\hat{\\beta_1})$. \n",
    "\n",
    "To use our boot_SE function we must create a function that takes a dataframe D and indices idx as its only arguments. But here we want to boostrap a specific regression model, specified by a model formula and data. How to do this? We define a generic function boot_OLS() for bootstrapping a regression model that takes a formula to define the corresponding regression. We use .clone() to create a copy of the formula which can be refit to the new dataframe. Any derived features, e.g. the ones derived by poly(), will be refit on the resampled dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boot_OLS(model_matrix, response,D,idx): \n",
    "    D_ = D.loc[idx]\n",
    "    Y_ = D_[response]\n",
    "    X_ = clone(model_matrix).fit_transform(D_)\n",
    "\n",
    "    return sm.OLS(Y_,X_).fit().params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But this cannot be feeded into boot_SE. We need to freeze the first two arguments since they will stay the same. We can use partial() from the functools module, which takes a function and freezes some of its parameters (starting from the left) returning a new function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "intercept     0.848807\n",
       "horsepower    0.007352\n",
       "dtype: float64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hp_func = partial(boot_OLS, MS(['horsepower']), 'mpg')\n",
    "\n",
    "hp_se = boot_SE(hp_func, Auto, B=1000, seed=10)\n",
    "hp_se\n",
    "# this means the SE for the intercept (beta0) is 0.84 \n",
    "#                SE for horsepower (beta1) is 0.007"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "intercept     0.717\n",
       "horsepower    0.006\n",
       "Name: std err, dtype: float64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we compare to the standard formulas for SE\n",
    "hp_model = sklearn_sm(sm.OLS, MS(['horsepower']))\n",
    "hp_model.fit(Auto[['horsepower']], Auto['mpg'])\n",
    "model_se = summarize(hp_model.results_)['std err']\n",
    "model_se"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The estimates differ because the standard formulas assume that $x_i$ are fixed and the variation comes only from the residuals. They also depend on $\\sigma^2$ which is an estimate and relies on the assumption that the model is correct. The bootstrap does not make such assumptions so it is more correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

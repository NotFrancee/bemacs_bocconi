{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib.pyplot import subplots\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, Lasso\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from ISLP import load_data\n",
    "from ISLP.models import ModelSpec as MS\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch specific imports\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import RMSprop\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "# utils\n",
    "from torchmetrics import MeanAbsoluteError, R2Score\n",
    "from torchinfo import summary\n",
    "from torchvision.io import read_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch lightning is more highlevel and allows us to skip boilerplate code\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.loggers import CSVLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n"
     ]
    }
   ],
   "source": [
    "# to make results consistent we seed everything\n",
    "from pytorch_lightning import seed_everything\n",
    "seed_everything(0, workers=True)\n",
    "torch.use_deterministic_algorithms(True, warn_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing datasets\n",
    "from torchvision.datasets import MNIST, CIFAR100\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "from torchvision.transforms import Resize, Normalize, CenterCrop, ToTensor\n",
    "\n",
    "# simpledatamodule and simplemodule are simpler versions of objects in pytorch_lightning\n",
    "# errortracker handles collections of targets and \n",
    "#   predictions over each mini-batch in the validation/test stage\n",
    "from ISLP.torch import SimpleDataModule, SimpleModule, ErrorTracker, rec_num_workers\n",
    "\n",
    "# utils to pull from the IMDb database \n",
    "from ISLP.torch.imdb import load_lookup, load_tensor, load_sparse, load_sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# glob finds all matching wildcard characters\n",
    "from glob import glob\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (10.9.1) Single Layer Network on Hitters Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hitters = load_data('Hitters').dropna()\n",
    "n = Hitters.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to_numpy converts pandas df to numpy arrays. We do this because we will use sklearn to fit lasso, and lasso needs this conversion. \n",
    "\n",
    "We also use LinearRegression from sklearn to facilitate the comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MS(Hitters.columns.drop('Salary'), intercept=False)\n",
    "X = model.fit_transform(Hitters).to_numpy()\n",
    "Y = Hitters['Salary'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "259.71528833146317"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we split into training and test data\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=1/3,random_state=1)\n",
    "\n",
    "hit_lm = LinearRegression().fit(X_train,Y_train)\n",
    "Yhat_test = hit_lm.predict(X_test) \n",
    "np.abs(Yhat_test - Y_test).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now fit the Lasso using sklearn. We use MAE rather than MSE to fit the model in this case. \n",
    "\n",
    "We create a cross-balidation grid and perform the cross-validation directly. \n",
    "\n",
    "We encode the pipeline in two steps: \n",
    "1) We normalize the features using StandardScaler() transform\n",
    "2) Fit the lasso without further normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler(with_mean=True, with_std=True)\n",
    "lasso = Lasso(warm_start=True, max_iter=30000)\n",
    "standard_lasso = Pipeline(steps=[('scaler', scaler), ('lasso', lasso)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to create a grid of values for $\\lambda$. We choose a grid of 100 values, uniform on the log scale from lam_max \n",
    "down to $0.01\\cdot lam_max$. \n",
    "\n",
    "Here lam_max is the smallest value of $\\lambda$ with an all-zero solution. \n",
    "This value equals the largest absolute inner product between any predictor and the (centered) response. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_s = scaler.fit_transform(X_train)\n",
    "n = X_s.shape[0]\n",
    "lam_max = np.fabs(X_s.T.dot(Y_train - Y_train.mean())).max() / n\n",
    "param_grid = {'alpha': np.exp(np.linspace(0,np.log(0.01), 100) ) * lam_max}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=KFold(n_splits=10, random_state=1, shuffle=True),\n",
       "             estimator=Lasso(max_iter=30000, warm_start=True),\n",
       "             param_grid={&#x27;alpha&#x27;: array([255.65755026, 244.03752004, 232.94563812, 222.35789935,\n",
       "       212.25138966, 202.60423642, 193.39556119, 184.60543446,\n",
       "       176.21483255, 168.20559645, 160.5603925 , 153.26267486,\n",
       "       146.29664975, 139.64724123, 133.3000586 , 127.24136521,\n",
       "       121.45...\n",
       "        10.81237873,  10.32093943,   9.8518368 ,   9.40405561,\n",
       "         8.97662677,   8.56862523,   8.17916799,   7.80741218,\n",
       "         7.45255325,   7.1138232 ,   6.79048896,   6.48185076,\n",
       "         6.18724064,   5.906021  ,   5.63758323,   5.38134637,\n",
       "         5.13675587,   4.90328239,   4.68042064,   4.4676883 ,\n",
       "         4.26462497,   4.07079118,   3.88576744,   3.70915331,\n",
       "         3.54056657,   3.37964236,   3.2260324 ,   3.07940424,\n",
       "         2.93944057,   2.80583846,   2.67830877,   2.5565755 ])},\n",
       "             scoring=&#x27;neg_mean_absolute_error&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=KFold(n_splits=10, random_state=1, shuffle=True),\n",
       "             estimator=Lasso(max_iter=30000, warm_start=True),\n",
       "             param_grid={&#x27;alpha&#x27;: array([255.65755026, 244.03752004, 232.94563812, 222.35789935,\n",
       "       212.25138966, 202.60423642, 193.39556119, 184.60543446,\n",
       "       176.21483255, 168.20559645, 160.5603925 , 153.26267486,\n",
       "       146.29664975, 139.64724123, 133.3000586 , 127.24136521,\n",
       "       121.45...\n",
       "        10.81237873,  10.32093943,   9.8518368 ,   9.40405561,\n",
       "         8.97662677,   8.56862523,   8.17916799,   7.80741218,\n",
       "         7.45255325,   7.1138232 ,   6.79048896,   6.48185076,\n",
       "         6.18724064,   5.906021  ,   5.63758323,   5.38134637,\n",
       "         5.13675587,   4.90328239,   4.68042064,   4.4676883 ,\n",
       "         4.26462497,   4.07079118,   3.88576744,   3.70915331,\n",
       "         3.54056657,   3.37964236,   3.2260324 ,   3.07940424,\n",
       "         2.93944057,   2.80583846,   2.67830877,   2.5565755 ])},\n",
       "             scoring=&#x27;neg_mean_absolute_error&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Lasso</label><div class=\"sk-toggleable__content\"><pre>Lasso(max_iter=30000, warm_start=True)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Lasso</label><div class=\"sk-toggleable__content\"><pre>Lasso(max_iter=30000, warm_start=True)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=10, random_state=1, shuffle=True),\n",
       "             estimator=Lasso(max_iter=30000, warm_start=True),\n",
       "             param_grid={'alpha': array([255.65755026, 244.03752004, 232.94563812, 222.35789935,\n",
       "       212.25138966, 202.60423642, 193.39556119, 184.60543446,\n",
       "       176.21483255, 168.20559645, 160.5603925 , 153.26267486,\n",
       "       146.29664975, 139.64724123, 133.3000586 , 127.24136521,\n",
       "       121.45...\n",
       "        10.81237873,  10.32093943,   9.8518368 ,   9.40405561,\n",
       "         8.97662677,   8.56862523,   8.17916799,   7.80741218,\n",
       "         7.45255325,   7.1138232 ,   6.79048896,   6.48185076,\n",
       "         6.18724064,   5.906021  ,   5.63758323,   5.38134637,\n",
       "         5.13675587,   4.90328239,   4.68042064,   4.4676883 ,\n",
       "         4.26462497,   4.07079118,   3.88576744,   3.70915331,\n",
       "         3.54056657,   3.37964236,   3.2260324 ,   3.07940424,\n",
       "         2.93944057,   2.80583846,   2.67830877,   2.5565755 ])},\n",
       "             scoring='neg_mean_absolute_error')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now we perform cross validation\n",
    "cv = KFold(10, shuffle=True, random_state=1)\n",
    "grid = GridSearchCV(lasso, param_grid, cv=cv, scoring='neg_mean_absolute_error')\n",
    "grid.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "257.23820107995016"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_lasso = grid.best_estimator_\n",
    "Yhat_test = trained_lasso.predict(X_test)\n",
    "np.fabs(Yhat_test - Y_test).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now specify the NN Model. Doing so requires us to specify classes specific to the model we want to fit. \n",
    "\n",
    "The way to do it in pytorch is to sub-class a generic representation of a network. \n",
    "\n",
    "* nn.Module is ubiquitous in pytorch and represents the mappings in the NN\n",
    "* flatten and sequential are used in forward to describe the map that this Module implements\n",
    "* sequential is a composition of 4 maps: \n",
    "    1) The input features are mapped to 50 dimensions, introducing in this case 19*50 \n",
    "     50 parameters for weights and intercepts of the map\n",
    "    2) This layer is mapped to a ReLU layer \n",
    "    3) A 40% dropout layer follows\n",
    "    4) Linear map down to 1 dimension again with a bias\n",
    "\n",
    "The total number of trainable parameters is $(19*50+50)+(50+1)=1051$.\n",
    "\n",
    "The package torchinfo provides a function summary() that summarizes this information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HittersModel(nn.Module): # nn.Model is ubiquitous in pytorch and represents the mappings in the NN. \n",
    "    def __init__(self, input_size) -> None:\n",
    "        super(HittersModel, self).__init__()\n",
    "        \n",
    "        # flatten and sequential are used in forward to describe the map that this module implements\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.sequential = nn.Sequential(nn.Linear(input_size, 50), nn.ReLU(), nn.Dropout(0.4), nn.Linear(50, 1))\n",
    "\n",
    "    def forward(self, x): \n",
    "        x = self.flatten(x)\n",
    "        return torch.flatten(self.sequential(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===================================================================================================================\n",
       "Layer (type:depth-idx)                   Input Shape               Output Shape              Param #\n",
       "===================================================================================================================\n",
       "HittersModel                             [175, 19]                 [175]                     --\n",
       "├─Flatten: 1-1                           [175, 19]                 [175, 19]                 --\n",
       "├─Sequential: 1-2                        [175, 19]                 [175, 1]                  --\n",
       "│    └─Linear: 2-1                       [175, 19]                 [175, 50]                 1,000\n",
       "│    └─ReLU: 2-2                         [175, 50]                 [175, 50]                 --\n",
       "│    └─Dropout: 2-3                      [175, 50]                 [175, 50]                 --\n",
       "│    └─Linear: 2-4                       [175, 50]                 [175, 1]                  51\n",
       "===================================================================================================================\n",
       "Total params: 1,051\n",
       "Trainable params: 1,051\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 0.18\n",
       "===================================================================================================================\n",
       "Input size (MB): 0.01\n",
       "Forward/backward pass size (MB): 0.07\n",
       "Params size (MB): 0.00\n",
       "Estimated Total Size (MB): 0.09\n",
       "==================================================================================================================="
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hit_model = HittersModel(X.shape[1])\n",
    "\n",
    "summary(hit_model, input_size=X_train.shape, col_names=[\"input_size\", \"output_size\", \"num_params\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab - Cross Validation and Bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from ISLP import load_data\n",
    "from ISLP.models import (ModelSpec as MS,\n",
    "summarize ,\n",
    "poly)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from sklearn.model_selection import \\\n",
    "(cross_validate ,\n",
    "KFold ,\n",
    "ShuffleSplit)\n",
    "from sklearn.base import clone\n",
    "from ISLP.models import sklearn_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation Set Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We explore the use of the validation set approach. \n",
    "\n",
    "We use train_test_split() to split the data into training and validation sets. Then we can fit a model using only the observations from the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Auto = load_data('Auto')\n",
    "Auto_train, Auto_valid = train_test_split(Auto, test_size=196, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_mm = MS(['horsepower'])\n",
    "X_train = hp_mm.fit_transform(Auto_train)\n",
    "y_train = Auto_train['mpg']\n",
    "model = sm.OLS(y_train, X_train)\n",
    "results = model.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now use the predict() method of results on the validation data. We also calculate the validation MSE for our model. It turns out our Test MSE is 23.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23.61661706966988"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid = hp_mm.transform(Auto_valid)\n",
    "y_valid = Auto_valid['mpg']\n",
    "valid_pred = results.predict(X_valid)\n",
    "np.mean((y_valid - valid_pred) ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's generalize calculating the Test MSE with a function and let's estimate it for linear, quadratic and cubic fits. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalMSE(terms, response, train, test): \n",
    "    mm = MS(terms)\n",
    "    X_train = mm.fit_transform(train)\n",
    "    y_train = train[response]\n",
    "\n",
    "    X_test = mm.transform(test)\n",
    "    y_test = test[response]\n",
    "\n",
    "    results = sm.OLS(y_train, X_train).fit()\n",
    "    test_pred = results.predict(X_test)\n",
    "\n",
    "    return np.mean((test_pred - y_test ) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([23.61661707, 18.76303135, 18.79694163])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE = np.zeros(3)\n",
    "\n",
    "for idx, degree in enumerate(range(1,4)): \n",
    "    MSE[idx] = evalMSE([poly('horsepower', degree)], 'mpg', Auto_train, Auto_valid)\n",
    "\n",
    "MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simplest way to cross validate in python is using sklearn, which has a different interface than statsmodels. \n",
    "\n",
    "cross_validate takes an optional parameter cv that indicates the K-fold for K-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19549935010445704"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "\n",
    "X, Y = Auto[['horsepower']], Auto['mpg']\n",
    "cv_results = cross_validate(model, X, Y, cv=10) # specifying cv does a k-fold cross validation\n",
    "# the fact that we provided the shape of the dataset means that we will perform Leave-One-Out CV (LOOCV)\n",
    "cv_err = np.mean(cv_results['test_score'])\n",
    "cv_err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We repeat this for various degrees of the polynomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     horsepower  degree_1\n",
      "0           130       130\n",
      "1           165       165\n",
      "2           150       150\n",
      "3           150       150\n",
      "4           140       140\n",
      "..          ...       ...\n",
      "387          86        86\n",
      "388          52        52\n",
      "389          84        84\n",
      "390          79        79\n",
      "391          82        82\n",
      "\n",
      "[392 rows x 2 columns]\n",
      "     horsepower  degree_2\n",
      "0           130     16900\n",
      "1           165     27225\n",
      "2           150     22500\n",
      "3           150     22500\n",
      "4           140     19600\n",
      "..          ...       ...\n",
      "387          86      7396\n",
      "388          52      2704\n",
      "389          84      7056\n",
      "390          79      6241\n",
      "391          82      6724\n",
      "\n",
      "[392 rows x 2 columns]\n",
      "     horsepower  degree_3\n",
      "0           130   2197000\n",
      "1           165   4492125\n",
      "2           150   3375000\n",
      "3           150   3375000\n",
      "4           140   2744000\n",
      "..          ...       ...\n",
      "387          86    636056\n",
      "388          52    140608\n",
      "389          84    592704\n",
      "390          79    493039\n",
      "391          82    551368\n",
      "\n",
      "[392 rows x 2 columns]\n",
      "     horsepower   degree_4\n",
      "0           130  285610000\n",
      "1           165  741200625\n",
      "2           150  506250000\n",
      "3           150  506250000\n",
      "4           140  384160000\n",
      "..          ...        ...\n",
      "387          86   54700816\n",
      "388          52    7311616\n",
      "389          84   49787136\n",
      "390          79   38950081\n",
      "391          82   45212176\n",
      "\n",
      "[392 rows x 2 columns]\n",
      "     horsepower      degree_5\n",
      "0           130   37129300000\n",
      "1           165  122298103125\n",
      "2           150   75937500000\n",
      "3           150   75937500000\n",
      "4           140   53782400000\n",
      "..          ...           ...\n",
      "387          86    4704270176\n",
      "388          52     380204032\n",
      "389          84    4182119424\n",
      "390          79    3077056399\n",
      "391          82    3707398432\n",
      "\n",
      "[392 rows x 2 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.19549935, -0.02532989, -0.24670234, -0.41961709, -0.53502275])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_error = np.zeros(5)\n",
    "\n",
    "Y = Auto['mpg']\n",
    "model = LinearRegression()\n",
    "\n",
    "for idx, degree in enumerate(range(1,6)): \n",
    "    col = f'degree_{degree}'\n",
    "    Auto[col] = np.power(Auto['horsepower'], degree)\n",
    "    X = Auto[[col]]\n",
    "    print(Auto[['horsepower', col]])\n",
    "\n",
    "    cv_results = cross_validate(model, \n",
    "                                X, \n",
    "                                Y, \n",
    "                                cv=10)\n",
    "    cv_error[idx] = np.mean(cv_results['test_score'])\n",
    "\n",
    "cv_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
